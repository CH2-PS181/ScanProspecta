{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ScanProspecta**"
      ],
      "metadata": {
        "id": "PgaAV6IC7kNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Library**"
      ],
      "metadata": {
        "id": "ren84lToj3_9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCCv0naE7I2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acaecb9e-afd4-4eca-8ceb-3e187a414666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Dataset**"
      ],
      "metadata": {
        "id": "QBc_WTAWBsxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/InferencePrince555/Resume-Dataset/resolve/main/updated_data_final_cleaned.csv"
      ],
      "metadata": {
        "id": "a38RznAhDFim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c31ad8-1d8e-4ff5-8fad-701cad66a3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-05 15:22:53--  https://huggingface.co/datasets/InferencePrince555/Resume-Dataset/resolve/main/updated_data_final_cleaned.csv\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/8a/ae/8aae04b8e17069856ddb28e3052e381c44ae2dc21356336bff549473bfda5ad1/c821343fe6a2a0e1bb70a08122615936c16af045981d632e6708a72977186c19?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27updated_data_final_cleaned.csv%3B+filename%3D%22updated_data_final_cleaned.csv%22%3B&response-content-type=text%2Fcsv&Expires=1702048973&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjA0ODk3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84YS9hZS84YWFlMDRiOGUxNzA2OTg1NmRkYjI4ZTMwNTJlMzgxYzQ0YWUyZGMyMTM1NjMzNmJmZjU0OTQ3M2JmZGE1YWQxL2M4MjEzNDNmZTZhMmEwZTFiYjcwYTA4MTIyNjE1OTM2YzE2YWYwNDU5ODFkNjMyZTY3MDhhNzI5NzcxODZjMTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=qW2SitRnvKfk9odwuCv4eJ%7EWSylT1qcvgMaBniKeJlmPD9BiHNnbs-7ArNfEHV817Tu9LWKSjl1igdJLMa47iEo4qM%7E%7EgP8NUcd9RPoXvO8%7EXPao4ytnHIdkArt42d29LuPWqeWHqaLZnWTfXFZ1rP6HFiKoYZJGOp3wxgwvmw1LxMM4wahRzqJyI88UJcZHfFAa21rXH9neS6XbeIRlp7-CqYNlmYFK0y4Bm9UZqHM1RyGE9aMqtweAwv9ULcTHwJfFfF8BLLhOBvlYGxyqV3Q9AlIrKZRfu7maTWIwMLDgNv2yWegtaoQucC0g%7ExYZQzAT4sMt6WRr0TZk%7EwUvpg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-12-05 15:22:53--  https://cdn-lfs.huggingface.co/repos/8a/ae/8aae04b8e17069856ddb28e3052e381c44ae2dc21356336bff549473bfda5ad1/c821343fe6a2a0e1bb70a08122615936c16af045981d632e6708a72977186c19?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27updated_data_final_cleaned.csv%3B+filename%3D%22updated_data_final_cleaned.csv%22%3B&response-content-type=text%2Fcsv&Expires=1702048973&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjA0ODk3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84YS9hZS84YWFlMDRiOGUxNzA2OTg1NmRkYjI4ZTMwNTJlMzgxYzQ0YWUyZGMyMTM1NjMzNmJmZjU0OTQ3M2JmZGE1YWQxL2M4MjEzNDNmZTZhMmEwZTFiYjcwYTA4MTIyNjE1OTM2YzE2YWYwNDU5ODFkNjMyZTY3MDhhNzI5NzcxODZjMTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=qW2SitRnvKfk9odwuCv4eJ%7EWSylT1qcvgMaBniKeJlmPD9BiHNnbs-7ArNfEHV817Tu9LWKSjl1igdJLMa47iEo4qM%7E%7EgP8NUcd9RPoXvO8%7EXPao4ytnHIdkArt42d29LuPWqeWHqaLZnWTfXFZ1rP6HFiKoYZJGOp3wxgwvmw1LxMM4wahRzqJyI88UJcZHfFAa21rXH9neS6XbeIRlp7-CqYNlmYFK0y4Bm9UZqHM1RyGE9aMqtweAwv9ULcTHwJfFfF8BLLhOBvlYGxyqV3Q9AlIrKZRfu7maTWIwMLDgNv2yWegtaoQucC0g%7ExYZQzAT4sMt6WRr0TZk%7EwUvpg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.27, 18.154.185.26, 18.154.185.64, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206425438 (197M) [text/csv]\n",
            "Saving to: ‘updated_data_final_cleaned.csv’\n",
            "\n",
            "updated_data_final_ 100%[===================>] 196.86M   213MB/s    in 0.9s    \n",
            "\n",
            "2023-12-05 15:22:54 (213 MB/s) - ‘updated_data_final_cleaned.csv’ saved [206425438/206425438]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/updated_data_final_cleaned.csv'\n",
        "preview = pd.read_csv(file_path)\n",
        "print(preview.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIrB3bobkpH8",
        "outputId": "21046c40-b71b-49a4-b800-49360690011d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              instruction  input  \\\n",
            "0  Generate a Resume for a Accountant Job    NaN   \n",
            "1  Generate a Resume for a Accountant Job    NaN   \n",
            "2  Generate a Resume for a Accountant Job    NaN   \n",
            "3  Generate a Resume for a Accountant Job    NaN   \n",
            "4  Generate a Resume for a Accountant Job    NaN   \n",
            "\n",
            "                                         Resume_test  \n",
            "0  ACCOUNTANT Professional Summary Results orient...  \n",
            "1  STAFF ACCOUNTANT Summary Flexible Accountant w...  \n",
            "2  STAFF ACCOUNTANT Summary Highly analytical and...  \n",
            "3  SENIOR ACCOUNTANT Summary A highly competent m...  \n",
            "4  SENIOR ACCOUNTANT Summary 11 years experience ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "h8PxZtxZo5MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Pandas DataFrame\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to extract job positions from 'instruction' column\n",
        "def extract_job_position(instruction):\n",
        "    # Split the text between 'for a' and 'Job'\n",
        "    start = 'for a '\n",
        "    end = ' Job'\n",
        "    job_position = instruction.split(start)[1].split(end)[0]\n",
        "    return job_position.lower()  # Convert to lowercase\n",
        "\n",
        "# Apply function to extract job positions and update 'instruction' column\n",
        "data['instruction'] = data['instruction'].apply(extract_job_position)\n",
        "\n",
        "# Function to convert text to lowercase for 'Resume_test' column\n",
        "def lowercase_text(text):\n",
        "    if isinstance(text, str):  # Check if the value is a string\n",
        "        return text.lower()   # Convert to lowercase\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Apply function to convert 'Resume_test' column to lowercase\n",
        "data['Resume_test'] = data['Resume_test'].apply(lowercase_text)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IECyq1KEpXPh",
        "outputId": "a820c78e-d53b-4f81-9a11-de8197650332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         instruction  input                                        Resume_test\n",
            "32476  web developer    NaN  software engineer span lsoftwarespan engineer ...\n",
            "32477  web developer    NaN  sr systems manager sr business manager sr span...\n",
            "32478  web developer    NaN  full stack net developer full stack net span l...\n",
            "32479  web developer    NaN  director of information systems director of in...\n",
            "32480  web developer    NaN  ux engineer ux engineer ux engineer redmond wa...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split Data**"
      ],
      "metadata": {
        "id": "305JsFr8v0wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training (80%) and temporary (20%) sets\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further splitting the temporary set into validation (50%) and test (50%) sets\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Displaying the shapes of the resulting sets\n",
        "print(\"Train set shape:\", train_data.shape)\n",
        "print(\"Validation set shape:\", val_data.shape)\n",
        "print(\"Test set shape:\", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXTUy8dtwLJo",
        "outputId": "d3a65b70-2862-43ab-dde5-d980c4198b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (25984, 3)\n",
            "Validation set shape: (3248, 3)\n",
            "Test set shape: (3249, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Model**"
      ],
      "metadata": {
        "id": "l-chDksPxISl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1KAdKDexNz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
